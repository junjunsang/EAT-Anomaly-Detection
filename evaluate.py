import torch
from torch.utils.data import DataLoader
from dataset import DCASE_Dataset
from tqdm import tqdm
import os
import numpy as np
from sklearn.metrics import roc_auc_score
import torch.nn.functional as F
import argparse

# ğŸ‘‡ ì—¬ê¸°ë¶€í„° model.pyë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½!
from model import EAT_Classifier

def evaluate_per_machine_type(k):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    encoder_save_path = "best_encoder_model.pth"
    embedding_library_path = "normal_embeddings.pt"

    if not os.path.exists(encoder_save_path) or not os.path.exists(embedding_library_path):
        print(f"í•„ìš”í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print("ëª¨ë¸ êµ¬ì¡°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤ (model.py ì„¤ì • ê³µìœ )...")
    
    # 1. ê»ë°ê¸° ëª¨ë¸ ìƒì„± (í‰ê°€ë§Œ í•  ê±°ë¼ num_classesëŠ” ì•„ë¬´ ìˆ«ìë‚˜ OK)
    # model.pyì— ìˆëŠ” LoRA ì„¤ì •(r=8, alpha=32 ë“±)ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    temp_model = EAT_Classifier(num_classes=1)
    
    # 2. í•„ìš”í•œ 'encoder' ë¶€ë¶„ë§Œ ë¶„ë¦¬
    encoder = temp_model.encoder

    print(f"'{encoder_save_path}'ì—ì„œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    encoder.load_state_dict(torch.load(encoder_save_path))
    encoder.to(device)
    encoder.eval()

    library = torch.load(embedding_library_path)
    normal_embeddings = library['embeddings'].to(device)

    print(f"'test' ë°ì´í„°ì…‹ì˜ ì´ìƒ ì ìˆ˜ë¥¼ K={k}ì¸ KNN ë°©ì‹ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤...")
    test_dataset = DCASE_Dataset("./dev_data", mode='test')
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)

    ground_truth_labels = []
    anomaly_scores = []
    machine_types = []

    with torch.no_grad():
        for spec, _, is_normal_batch, machine_type_str_batch in tqdm(test_loader, desc="Evaluating"):
            spec = spec.to(device)
            is_normal = is_normal_batch[0].item()
            machine_type = machine_type_str_batch[0]
            
            # ì¸ì½”ë” í†µê³¼
            outputs = encoder(spec)
            
            # CLS í† í° ì¶”ì¶œ (ì‹œí€€ìŠ¤ì˜ 0ë²ˆì§¸ ë²¡í„°)
            if hasattr(outputs, "last_hidden_state"):
                test_embedding = outputs.last_hidden_state[:, 0, :]
            else:
                test_embedding = outputs[:, 0, :]
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚° (1 - ìœ ì‚¬ë„ = ê±°ë¦¬)
            # test_embedding: (1, dim), normal_embeddings: (N, dim) -> ë¸Œë¡œë“œìºìŠ¤íŒ… ë¨
            distances = 1 - F.cosine_similarity(test_embedding, normal_embeddings)
            
            # ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ì´ì›ƒ ì°¾ê¸°
            top_k_distances, _ = torch.topk(distances, k, largest=False)
            
            # í‰ê·  ê±°ë¦¬ë¥¼ ì´ìƒ ì ìˆ˜(Anomaly Score)ë¡œ ì‚¬ìš©
            score = torch.mean(top_k_distances).item()
            
            anomaly_scores.append(score)
            ground_truth_labels.append(0 if is_normal else 1) # 0: normal, 1: anomaly
            machine_types.append(machine_type)

    print("\n--- ë¶„ì„ ì™„ë£Œ ---")
    
    # ì „ì²´ ì„±ëŠ¥
    overall_auroc = roc_auc_score(ground_truth_labels, anomaly_scores)
    print(f"ì „ì²´ í‰ê·  ì„±ëŠ¥ (Overall AUROC): {overall_auroc:.4f}\n")
    
    # íƒ€ì…ë³„ ì„±ëŠ¥
    print("--- ê¸°ê³„ íƒ€ì…ë³„ ì„±ëŠ¥ ---")
    unique_machine_types = sorted(list(set(machine_types)))
    scores = np.array(anomaly_scores)
    labels = np.array(ground_truth_labels)
    types = np.array(machine_types)
    
    for machine_type in unique_machine_types:
        mask = (types == machine_type)
        type_scores = scores[mask]
        type_labels = labels[mask]
        
        if len(np.unique(type_labels)) > 1:
            type_auroc = roc_auc_score(type_labels, type_scores)
            print(f"  - {machine_type.ljust(10)}: {type_auroc:.4f}")
        else:
            print(f"  - {machine_type.ljust(10)}: (ë¹„ì •ìƒ ìƒ˜í”Œ ì—†ìŒ)")
            
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="KNN ê¸°ë°˜ ì´ìƒ íƒì§€ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (íƒ€ì…ë³„ ë¶„ì„ í¬í•¨)")
    parser.add_argument("-k", type=int, default=1, help="ì´ìƒ ì ìˆ˜ ê³„ì‚°ì— ì‚¬ìš©í•  ì´ì›ƒ(K)ì˜ ìˆ˜")
    args = parser.parse_args()
    
    evaluate_per_machine_type(args.k)